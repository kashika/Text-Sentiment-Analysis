{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import training data in train\n",
    "train = pd.read_csv(\n",
    "    filepath_or_buffer='train.dat', \n",
    "    header=0, \n",
    "    sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>she had another song out recently but it didn'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wellity! i think ima gonna clean my room :| Ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Bug in damn cod4 system link. My map pack isnt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>weeooow, i feel fat.... i remember when i used...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>mmmm now you're speaking my language! (Unfortu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               Text\n",
       "0          2  she had another song out recently but it didn'...\n",
       "1          2  wellity! i think ima gonna clean my room :| Ga...\n",
       "2          2  Bug in damn cod4 system link. My map pack isnt...\n",
       "3          8  weeooow, i feel fat.... i remember when i used...\n",
       "4          7  mmmm now you're speaking my language! (Unfortu..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.348097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.114712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiment\n",
       "count  31000.000000\n",
       "mean       4.348097\n",
       "std        3.114712\n",
       "min        1.000000\n",
       "25%        2.000000\n",
       "50%        3.000000\n",
       "75%        7.000000\n",
       "max       11.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4257</td>\n",
       "      <td>4249</td>\n",
       "      <td>I miss you</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7006</td>\n",
       "      <td>6979</td>\n",
       "      <td>I am lost. Please help me find a good home.</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7131</td>\n",
       "      <td>7074</td>\n",
       "      <td>Thanks</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3141</td>\n",
       "      <td>3095</td>\n",
       "      <td>I just received a mothers day card from my lov...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "      <td>If you don't want to come then don't come. JEE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>617</td>\n",
       "      <td>616</td>\n",
       "      <td>Hi I have uploaded 5 completely new Chinese Le...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1759</td>\n",
       "      <td>1758</td>\n",
       "      <td>Thought you might be interested in @TweetPhoto...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1458</td>\n",
       "      <td>1458</td>\n",
       "      <td>Morning Twitterland! Countdown to TCI begins a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1072</td>\n",
       "      <td>1072</td>\n",
       "      <td>i hate i hate i hate i hate i hate i hate moth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4311</td>\n",
       "      <td>4280</td>\n",
       "      <td>good morning</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>I am sooooooo bored in textiles !</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Text                                                               \n",
       "          count unique                                                top freq\n",
       "sentiment                                                                     \n",
       "1          4257   4249                                         I miss you    3\n",
       "2          7006   6979        I am lost. Please help me find a good home.    9\n",
       "3          7131   7074                                             Thanks    8\n",
       "4          3141   3095  I just received a mothers day card from my lov...   10\n",
       "5            96     96  If you don't want to come then don't come. JEE...    1\n",
       "6           617    616  Hi I have uploaded 5 completely new Chinese Le...    2\n",
       "7          1759   1758  Thought you might be interested in @TweetPhoto...    2\n",
       "8          1458   1458  Morning Twitterland! Countdown to TCI begins a...    1\n",
       "9          1072   1072  i hate i hate i hate i hate i hate i hate moth...    1\n",
       "10         4311   4280                                       good morning    4\n",
       "11          149    149                  I am sooooooo bored in textiles !    1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby('sentiment').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the text in training data to string\n",
    "train['Text']=train['Text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['length'] = train['Text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>she had another song out recently but it didn'...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wellity! i think ima gonna clean my room :| Ga...</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Bug in damn cod4 system link. My map pack isnt...</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>weeooow, i feel fat.... i remember when i used...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>mmmm now you're speaking my language! (Unfortu...</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               Text  length\n",
       "0          2  she had another song out recently but it didn'...      66\n",
       "1          2  wellity! i think ima gonna clean my room :| Ga...     126\n",
       "2          2  Bug in damn cod4 system link. My map pack isnt...      54\n",
       "3          8  weeooow, i feel fat.... i remember when i used...     120\n",
       "4          7  mmmm now you're speaking my language! (Unfortu...     129"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data using Porter Stemmer to normalize the data for similar words with different spellings to mean the same\n",
    "from nltk.stem import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "def stem_sentences(sentence):\n",
    "    tokens = sentence.split(\" \")\n",
    "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "train['Text']=train['Text'].apply(stem_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    she had anoth song out recent but it didn't ge...\n",
       "1    wellity! i think ima gonna clean my room :| ga...\n",
       "2    bug in damn cod4 system link. My map pack isnt...\n",
       "3    weeooow, i feel fat.... i rememb when i use to...\n",
       "4    mmmm now you'r speak my language! (unfortunate...\n",
       "5                              really?? I feel special\n",
       "6            don't you procrastinate!   (like I do...)\n",
       "7    ive been want 2 but will be gone 4 2 mo. &amp;...\n",
       "8     sushi two night in a row isn't that wrong is it?\n",
       "9          haha i get my senior licens next friday!!!!\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Remove numerical data from the test file\n",
    "import re\n",
    "for i in range(len(train)):\n",
    "    train['Text'][i] = re.sub('\\d', '', train['Text'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    she had anoth song out recent but it didn't ge...\n",
       "1    wellity! i think ima gonna clean my room :| ga...\n",
       "2    bug in damn cod system link. My map pack isnt ...\n",
       "3    weeooow, i feel fat.... i rememb when i use to...\n",
       "4    mmmm now you'r speak my language! (unfortunate...\n",
       "5                              really?? I feel special\n",
       "6            don't you procrastinate!   (like I do...)\n",
       "7    ive been want  but will be gone   mo. &amp; ha...\n",
       "8     sushi two night in a row isn't that wrong is it?\n",
       "9          haha i get my senior licens next friday!!!!\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the data - remove punctuation, remove stopwords and return clean words in lower case\n",
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    1. Remove Punctuation\n",
    "    2. remove stopwords\n",
    "    3. return list of clean words\n",
    "    \"\"\"\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english') ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    she had anoth song out recent but it didn't ge...\n",
       "1    wellity! i think ima gonna clean my room :| ga...\n",
       "2    bug in damn cod system link. My map pack isnt ...\n",
       "3    weeooow, i feel fat.... i rememb when i use to...\n",
       "4    mmmm now you'r speak my language! (unfortunate...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data into training and testing data\n",
    "msg_train, msg_text, label_train, label_text =train_test_split(train['Text'],train['sentiment'], test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=100, gamma - 0.001\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =100,kernel='linear', gamma = 0.001))\n",
    "])\n",
    "pipeline.fit(msg_train,label_train)\n",
    "predictions1 = pipeline.predict(msg_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28       453\n",
      "          2       0.32      0.39      0.35       677\n",
      "          3       0.34      0.39      0.36       719\n",
      "          4       0.34      0.30      0.32       326\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.17      0.09      0.12        53\n",
      "          7       0.06      0.06      0.06       165\n",
      "          8       0.09      0.06      0.07       130\n",
      "          9       0.28      0.13      0.18       115\n",
      "         10       0.31      0.22      0.26       428\n",
      "         11       0.40      0.08      0.14        24\n",
      "\n",
      "avg / total       0.29      0.29      0.29      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_text, predictions1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28       453\n",
      "          2       0.32      0.39      0.35       677\n",
      "          3       0.34      0.39      0.36       719\n",
      "          4       0.34      0.30      0.32       326\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.17      0.09      0.12        53\n",
      "          7       0.06      0.06      0.06       165\n",
      "          8       0.09      0.06      0.07       130\n",
      "          9       0.28      0.13      0.18       115\n",
      "         10       0.31      0.22      0.26       428\n",
      "         11       0.40      0.08      0.14        24\n",
      "\n",
      "avg / total       0.29      0.29      0.29      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=100, gamma - 0.01\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline1 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =100,kernel='linear', gamma = 0.01))\n",
    "])\n",
    "pipeline1.fit(msg_train,label_train)\n",
    "predictions11 = pipeline1.predict(msg_text)\n",
    "print(classification_report(label_text, predictions11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.31      0.28       453\n",
      "          2       0.32      0.39      0.35       677\n",
      "          3       0.34      0.39      0.36       719\n",
      "          4       0.34      0.30      0.32       326\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.17      0.09      0.12        53\n",
      "          7       0.06      0.06      0.06       165\n",
      "          8       0.09      0.06      0.07       130\n",
      "          9       0.28      0.13      0.18       115\n",
      "         10       0.31      0.22      0.26       428\n",
      "         11       0.40      0.08      0.14        24\n",
      "\n",
      "avg / total       0.29      0.29      0.29      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=100, gamma - 0.1\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline2 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =100,kernel='linear', gamma = 0.1))\n",
    "])\n",
    "pipeline2.fit(msg_train,label_train)\n",
    "predictions12 = pipeline2.predict(msg_text)\n",
    "print(classification_report(label_text, predictions12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.29      0.28       453\n",
      "          2       0.33      0.41      0.36       677\n",
      "          3       0.33      0.38      0.35       719\n",
      "          4       0.37      0.35      0.36       326\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.15      0.08      0.10        53\n",
      "          7       0.09      0.07      0.08       165\n",
      "          8       0.08      0.03      0.04       130\n",
      "          9       0.28      0.13      0.18       115\n",
      "         10       0.29      0.24      0.26       428\n",
      "         11       0.40      0.08      0.14        24\n",
      "\n",
      "avg / total       0.29      0.30      0.29      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=10, gamma - 0.1\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline3 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =10,kernel='linear', gamma = 0.1))\n",
    "])\n",
    "pipeline3.fit(msg_train,label_train)\n",
    "predictions13 = pipeline3.predict(msg_text)\n",
    "print(classification_report(label_text, predictions13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.31      0.21      0.25       400\n",
      "          2       0.36      0.52      0.42       699\n",
      "          3       0.35      0.55      0.43       702\n",
      "          4       0.48      0.35      0.40       313\n",
      "          5       0.00      0.00      0.00        11\n",
      "          6       0.00      0.00      0.00        71\n",
      "          7       0.47      0.03      0.06       210\n",
      "          8       0.00      0.00      0.00       142\n",
      "          9       0.50      0.19      0.27       108\n",
      "         10       0.34      0.34      0.34       427\n",
      "         11       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.34      0.36      0.33      3100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 0.01\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline4 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 0.01))\n",
    "])\n",
    "pipeline4.fit(msg_train,label_train)\n",
    "predictions14 = pipeline4.predict(msg_text)\n",
    "print(classification_report(label_text, predictions14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.31      0.21      0.25       400\n",
      "          2       0.36      0.52      0.42       699\n",
      "          3       0.35      0.55      0.43       702\n",
      "          4       0.48      0.35      0.40       313\n",
      "          5       0.00      0.00      0.00        11\n",
      "          6       0.00      0.00      0.00        71\n",
      "          7       0.47      0.03      0.06       210\n",
      "          8       0.00      0.00      0.00       142\n",
      "          9       0.50      0.19      0.27       108\n",
      "         10       0.34      0.34      0.34       427\n",
      "         11       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.34      0.36      0.33      3100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 0.1\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline5 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 0.1))\n",
    "])\n",
    "pipeline5.fit(msg_train,label_train)\n",
    "predictions15 = pipeline5.predict(msg_text)\n",
    "print(classification_report(label_text, predictions15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_train, msg_text, label_train, label_text =train_test_split(train['Text'],train['sentiment'], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.30      0.33      0.31       447\n",
      "          2       0.36      0.41      0.39       728\n",
      "          3       0.34      0.40      0.37       707\n",
      "          4       0.44      0.37      0.40       306\n",
      "          5       0.00      0.00      0.00         7\n",
      "          6       0.00      0.00      0.00        66\n",
      "          7       0.17      0.09      0.12       170\n",
      "          8       0.09      0.04      0.06       142\n",
      "          9       0.37      0.23      0.29       103\n",
      "         10       0.34      0.37      0.36       412\n",
      "         11       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.32      0.34      0.33      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=5, gamma - 0.1\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline6 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =5,kernel='linear', gamma = .1))\n",
    "])\n",
    "pipeline6.fit(msg_train,label_train)\n",
    "predictions16 = pipeline6.predict(msg_text)\n",
    "print(classification_report(label_text, predictions16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.29      0.34      0.31       447\n",
      "          2       0.36      0.39      0.38       728\n",
      "          3       0.34      0.40      0.37       707\n",
      "          4       0.43      0.36      0.39       306\n",
      "          5       0.00      0.00      0.00         7\n",
      "          6       0.00      0.00      0.00        66\n",
      "          7       0.14      0.10      0.12       170\n",
      "          8       0.12      0.06      0.08       142\n",
      "          9       0.35      0.22      0.27       103\n",
      "         10       0.33      0.33      0.33       412\n",
      "         11       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.32      0.33      0.32      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=10, gamma - 0.1\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline7 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =10,kernel='linear', gamma = .1))\n",
    "])\n",
    "pipeline7.fit(msg_train,label_train)\n",
    "predictions17 = pipeline7.predict(msg_text)\n",
    "print(classification_report(label_text, predictions17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.35      0.26      0.30       658\n",
      "          2       0.35      0.47      0.40      1029\n",
      "          3       0.36      0.53      0.43      1086\n",
      "          4       0.53      0.39      0.45       491\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.00      0.00      0.00        95\n",
      "          7       0.35      0.03      0.06       267\n",
      "          8       0.29      0.02      0.04       205\n",
      "          9       0.45      0.17      0.25       148\n",
      "         10       0.33      0.35      0.34       634\n",
      "         11       0.00      0.00      0.00        27\n",
      "\n",
      "avg / total       0.36      0.36      0.34      4650\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_text, label_train, label_text =train_test_split(train['Text'],train['sentiment'], test_size=0.15)\n",
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 1\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline8 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 1))\n",
    "])\n",
    "pipeline8.fit(msg_train,label_train)\n",
    "predictions18 = pipeline8.predict(msg_text)\n",
    "print(classification_report(label_text, predictions18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.33      0.21      0.25       550\n",
      "          2       0.35      0.52      0.42       833\n",
      "          3       0.37      0.54      0.44       892\n",
      "          4       0.52      0.39      0.44       353\n",
      "          5       0.00      0.00      0.00        12\n",
      "          6       0.00      0.00      0.00        63\n",
      "          7       0.44      0.03      0.06       206\n",
      "          8       0.30      0.02      0.03       168\n",
      "          9       0.43      0.17      0.25       132\n",
      "         10       0.35      0.36      0.36       488\n",
      "         11       0.00      0.00      0.00        23\n",
      "\n",
      "avg / total       0.36      0.37      0.34      3720\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_text, label_train, label_text =train_test_split(train['Text'],train['sentiment'], test_size=0.12)\n",
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 1\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline23 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 1))\n",
    "])\n",
    "pipeline23.fit(msg_train,label_train)\n",
    "predictions33 = pipeline23.predict(msg_text)\n",
    "print(classification_report(label_text, predictions33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.40      0.27      0.32       663\n",
      "          2       0.35      0.50      0.41      1035\n",
      "          3       0.37      0.55      0.44      1096\n",
      "          4       0.48      0.39      0.43       445\n",
      "          5       0.00      0.00      0.00        12\n",
      "          6       0.00      0.00      0.00        92\n",
      "          7       0.47      0.03      0.06       256\n",
      "          8       0.22      0.01      0.02       224\n",
      "          9       0.51      0.19      0.28       150\n",
      "         10       0.39      0.39      0.39       657\n",
      "         11       0.00      0.00      0.00        20\n",
      "\n",
      "avg / total       0.38      0.38      0.35      4650\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_text, label_train, label_text =train_test_split(train['Text'],train['sentiment'], test_size=0.15)\n",
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 1\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline24 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 0.1))\n",
    "])\n",
    "pipeline24.fit(msg_train,label_train)\n",
    "predictions34 = pipeline24.predict(msg_text)\n",
    "print(classification_report(label_text, predictions34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.38      0.26      0.31       515\n",
      "          2       0.35      0.49      0.41       843\n",
      "          3       0.36      0.54      0.43       848\n",
      "          4       0.56      0.44      0.49       404\n",
      "          5       0.00      0.00      0.00        10\n",
      "          6       0.00      0.00      0.00        73\n",
      "          7       0.32      0.04      0.08       211\n",
      "          8       0.11      0.01      0.01       145\n",
      "          9       0.50      0.19      0.28       130\n",
      "         10       0.37      0.36      0.37       525\n",
      "         11       0.00      0.00      0.00        16\n",
      "\n",
      "avg / total       0.37      0.38      0.35      3720\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_text, label_train, label_text =train_test_split(train['Text'],train['sentiment'], test_size=0.12)\n",
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 1\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline25 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 1))\n",
    "])\n",
    "pipeline25.fit(msg_train,label_train)\n",
    "predictions35 = pipeline25.predict(msg_text)\n",
    "print(classification_report(label_text, predictions35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.37      0.24      0.29       425\n",
      "          2       0.34      0.49      0.40       651\n",
      "          3       0.33      0.53      0.41       696\n",
      "          4       0.55      0.39      0.45       365\n",
      "          5       0.00      0.00      0.00         8\n",
      "          6       0.00      0.00      0.00        60\n",
      "          7       0.50      0.06      0.11       179\n",
      "          8       0.10      0.01      0.01       129\n",
      "          9       0.33      0.12      0.17        94\n",
      "         10       0.40      0.37      0.38       478\n",
      "         11       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.37      0.37      0.34      3100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 0.01\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline9 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 1))\n",
    "])\n",
    "pipeline9.fit(msg_train,label_train)\n",
    "predictions19 = pipeline9.predict(msg_text)\n",
    "print(classification_report(label_text, predictions19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.34      0.24      0.28       873\n",
      "          2       0.34      0.47      0.39      1378\n",
      "          3       0.35      0.55      0.43      1394\n",
      "          4       0.50      0.37      0.43       656\n",
      "          5       0.00      0.00      0.00        19\n",
      "          6       0.00      0.00      0.00       126\n",
      "          7       0.44      0.04      0.07       374\n",
      "          8       0.20      0.02      0.03       284\n",
      "          9       0.51      0.19      0.28       212\n",
      "         10       0.37      0.37      0.37       863\n",
      "         11       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.36      0.36      0.33      6200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 10\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline10 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 10))\n",
    "])\n",
    "pipeline10.fit(msg_train,label_train)\n",
    "predictions20 = pipeline10.predict(msg_text)\n",
    "print(classification_report(label_text, predictions20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.37      0.24      0.29       425\n",
      "          2       0.34      0.49      0.40       651\n",
      "          3       0.33      0.53      0.41       696\n",
      "          4       0.55      0.39      0.45       365\n",
      "          5       0.00      0.00      0.00         8\n",
      "          6       0.00      0.00      0.00        60\n",
      "          7       0.50      0.06      0.11       179\n",
      "          8       0.10      0.01      0.01       129\n",
      "          9       0.33      0.12      0.17        94\n",
      "         10       0.40      0.37      0.38       478\n",
      "         11       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.37      0.37      0.34      3100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 100\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline11 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 100))\n",
    "])\n",
    "pipeline11.fit(msg_train,label_train)\n",
    "predictions21 = pipeline11.predict(msg_text)\n",
    "print(classification_report(label_text, predictions21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.37      0.24      0.29       425\n",
      "          2       0.34      0.49      0.40       651\n",
      "          3       0.33      0.53      0.41       696\n",
      "          4       0.55      0.39      0.45       365\n",
      "          5       0.00      0.00      0.00         8\n",
      "          6       0.00      0.00      0.00        60\n",
      "          7       0.50      0.06      0.11       179\n",
      "          8       0.10      0.01      0.01       129\n",
      "          9       0.33      0.12      0.17        94\n",
      "         10       0.40      0.37      0.38       478\n",
      "         11       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.37      0.37      0.34      3100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 1000\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline12 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 1000))\n",
    "])\n",
    "pipeline12.fit(msg_train,label_train)\n",
    "predictions22 = pipeline12.predict(msg_text)\n",
    "print(classification_report(label_text, predictions22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.32      0.22      0.26       429\n",
      "          2       0.33      0.48      0.39       675\n",
      "          3       0.36      0.55      0.43       707\n",
      "          4       0.55      0.39      0.46       331\n",
      "          5       0.00      0.00      0.00         6\n",
      "          6       0.00      0.00      0.00        68\n",
      "          7       0.30      0.03      0.06       192\n",
      "          8       0.25      0.01      0.03       146\n",
      "          9       0.49      0.20      0.28        92\n",
      "         10       0.34      0.35      0.34       437\n",
      "         11       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.35      0.36      0.33      3100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 100\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline13 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 100))\n",
    "])\n",
    "pipeline13.fit(msg_train,label_train)\n",
    "predictions23 = pipeline13.predict(msg_text)\n",
    "print(classification_report(label_text, predictions23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.32      0.22      0.26       429\n",
      "          2       0.33      0.48      0.39       675\n",
      "          3       0.36      0.55      0.43       707\n",
      "          4       0.55      0.39      0.46       331\n",
      "          5       0.00      0.00      0.00         6\n",
      "          6       0.00      0.00      0.00        68\n",
      "          7       0.30      0.03      0.06       192\n",
      "          8       0.25      0.01      0.03       146\n",
      "          9       0.49      0.20      0.28        92\n",
      "         10       0.34      0.35      0.34       437\n",
      "         11       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.35      0.36      0.33      3100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 200\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline14 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 200))\n",
    "])\n",
    "pipeline14.fit(msg_train,label_train)\n",
    "predictions24 = pipeline14.predict(msg_text)\n",
    "print(classification_report(label_text, predictions24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.32      0.22      0.26       429\n",
      "          2       0.33      0.48      0.39       675\n",
      "          3       0.36      0.55      0.43       707\n",
      "          4       0.55      0.39      0.46       331\n",
      "          5       0.00      0.00      0.00         6\n",
      "          6       0.00      0.00      0.00        68\n",
      "          7       0.30      0.03      0.06       192\n",
      "          8       0.25      0.01      0.03       146\n",
      "          9       0.49      0.20      0.28        92\n",
      "         10       0.34      0.35      0.34       437\n",
      "         11       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.35      0.36      0.33      3100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 2000\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline15 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 2000))\n",
    "])\n",
    "pipeline15.fit(msg_train,label_train)\n",
    "predictions25 = pipeline15.predict(msg_text)\n",
    "print(classification_report(label_text, predictions25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      0.29      0.27       429\n",
      "          2       0.31      0.39      0.35       675\n",
      "          3       0.35      0.41      0.38       707\n",
      "          4       0.43      0.36      0.39       331\n",
      "          5       0.00      0.00      0.00         6\n",
      "          6       0.00      0.00      0.00        68\n",
      "          7       0.10      0.06      0.08       192\n",
      "          8       0.11      0.07      0.08       146\n",
      "          9       0.24      0.17      0.20        92\n",
      "         10       0.34      0.30      0.32       437\n",
      "         11       0.00      0.00      0.00        17\n",
      "\n",
      "avg / total       0.30      0.31      0.30      3100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=10, gamma - 200\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline16 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =10,kernel='linear', gamma = 200))\n",
    "])\n",
    "pipeline16.fit(msg_train,label_train)\n",
    "predictions26 = pipeline16.predict(msg_text)\n",
    "print(classification_report(label_text, predictions26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.36      0.25      0.30       428\n",
      "          2       0.35      0.50      0.41       689\n",
      "          3       0.37      0.55      0.44       733\n",
      "          4       0.48      0.40      0.44       313\n",
      "          5       0.00      0.00      0.00        11\n",
      "          6       0.00      0.00      0.00        71\n",
      "          7       0.24      0.03      0.05       185\n",
      "          8       0.25      0.01      0.01       141\n",
      "          9       0.52      0.20      0.29       110\n",
      "         10       0.38      0.37      0.37       407\n",
      "         11       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.36      0.37      0.34      3100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# filter number \n",
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 1\n",
    "#Fit the model and predict the outcome for test data\n",
    "\n",
    "pipeline17 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 1))\n",
    "])\n",
    "pipeline17.fit(msg_train,label_train)\n",
    "predictions27 = pipeline17.predict(msg_text)\n",
    "print(classification_report(label_text, predictions27))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_train, msg_text, label_train, label_text =train_test_split(train['Text'],train['sentiment'], test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.34      0.23      0.27       846\n",
      "          2       0.36      0.51      0.42      1405\n",
      "          3       0.35      0.53      0.42      1415\n",
      "          4       0.53      0.39      0.45       623\n",
      "          5       0.00      0.00      0.00        18\n",
      "          6       0.00      0.00      0.00       132\n",
      "          7       0.29      0.04      0.07       335\n",
      "          8       0.09      0.01      0.01       280\n",
      "          9       0.48      0.17      0.25       222\n",
      "         10       0.35      0.34      0.35       894\n",
      "         11       0.00      0.00      0.00        30\n",
      "\n",
      "avg / total       0.35      0.37      0.34      6200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using SVC, c=1, gamma - 1\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline18 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',SVC(C =1,kernel='linear', gamma = 1))\n",
    "])\n",
    "pipeline18.fit(msg_train,label_train)\n",
    "predictions28 = pipeline18.predict(msg_text)\n",
    "print(classification_report(label_text, predictions28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_train, msg_text, label_train, label_text =train_test_split(train['Text'],train['sentiment'], test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.32      0.20      0.25       411\n",
      "          2       0.35      0.49      0.40       698\n",
      "          3       0.36      0.56      0.44       711\n",
      "          4       0.52      0.40      0.45       351\n",
      "          5       0.00      0.00      0.00         8\n",
      "          6       0.00      0.00      0.00        55\n",
      "          7       0.22      0.03      0.05       170\n",
      "          8       0.22      0.03      0.05       148\n",
      "          9       0.39      0.19      0.26       110\n",
      "         10       0.37      0.32      0.34       428\n",
      "         11       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.35      0.36      0.34      3100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using Ranfom Forest Classification, n_estimators=100\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline19 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',RandomForestClassifier(n_estimators=100))\n",
    "])\n",
    "pipeline19.fit(msg_train,label_train)\n",
    "predictions29 = pipeline19.predict(msg_text)\n",
    "print(classification_report(label_text, predictions29))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.35      0.19      0.24       873\n",
      "          2       0.34      0.47      0.39      1378\n",
      "          3       0.35      0.59      0.44      1394\n",
      "          4       0.48      0.39      0.43       656\n",
      "          5       0.00      0.00      0.00        19\n",
      "          6       0.00      0.00      0.00       126\n",
      "          7       0.44      0.05      0.09       374\n",
      "          8       0.09      0.01      0.01       284\n",
      "          9       0.45      0.19      0.27       212\n",
      "         10       0.34      0.32      0.33       863\n",
      "         11       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.35      0.36      0.33      6200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kashi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using Ranfom Forest Classification, n_estimators=3000\n",
    "#Fit the model and predict the outcome for test data\n",
    "pipeline20 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',RandomForestClassifier(n_estimators=3000))\n",
    "])\n",
    "pipeline20.fit(msg_train,label_train)\n",
    "predictions30 = pipeline20.predict(msg_text)\n",
    "print(classification_report(label_text, predictions30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=1000)\n",
    "params = {'class_weight':['balanced']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use Pipeline method to build the predictive model\n",
    "#Classification using Ranfom Forest Classification, n_estimators=3000\n",
    "#Fit the model and predict the outcome for test dat\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipeline21 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',GridSearchCV(estimator=clf, param_grid=params, cv=5))\n",
    "])\n",
    "pipeline21.fit(msg_train,label_train)\n",
    "predictions31 = pipeline31.predict(msg_text)\n",
    "print(classification_report(label_text, predictions31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipeline31' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-87e55e1ceed8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m ])\n\u001b[0;32m     11\u001b[0m \u001b[0mpipeline21\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mpredictions31\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline31\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions31\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipeline31' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "#use Pipeline method to build the predictive model\n",
    "#Classification using Gradient Booster\n",
    "#Fit the model and predict the outcome for test dat\n",
    "\n",
    "pipeline21 =Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer=text_process)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('Classifier',GradientBoostingClassifier(learning_rate=.1,n_estimators=200))\n",
    "])\n",
    "pipeline21.fit(msg_train,label_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.40      0.21      0.27       873\n",
      "          2       0.36      0.37      0.36      1378\n",
      "          3       0.32      0.63      0.42      1394\n",
      "          4       0.49      0.38      0.42       656\n",
      "          5       0.00      0.00      0.00        19\n",
      "          6       0.01      0.01      0.01       126\n",
      "          7       0.26      0.04      0.07       374\n",
      "          8       0.11      0.02      0.04       284\n",
      "          9       0.30      0.22      0.25       212\n",
      "         10       0.36      0.27      0.31       863\n",
      "         11       0.00      0.00      0.00        21\n",
      "\n",
      "avg / total       0.34      0.34      0.32      6200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions31 = pipeline21.predict(msg_text)\n",
    "print(classification_report(label_text, predictions31))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read test data into test\n",
    "testfile = pd.read_csv(\n",
    "    filepath_or_buffer='test.dat', \n",
    "    header=None, \n",
    "    sep='\\t',skip_blank_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert test data into string\n",
    "testfile[0]=testfile[0].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Your still thinking?  Cheer up Buddy )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forecast in sf for friday, may 29: 66 degrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>driving past Tattered Cover w/o stopping  prom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wowzer! It's very windy. Not good for my aller...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Start of diet today  I think I have to face I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0             Your still thinking?  Cheer up Buddy )\n",
       "1     forecast in sf for friday, may 29: 66 degrees.\n",
       "2  driving past Tattered Cover w/o stopping  prom...\n",
       "3  Wowzer! It's very windy. Not good for my aller...\n",
       "4  Start of diet today  I think I have to face I ..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testfile.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the data using Porter Stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "def stem_sentences(sentence):\n",
    "    tokens = sentence.split(\" \")\n",
    "    stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
    "    return ' '.join(stemmed_tokens)\n",
    "\n",
    "testfile[0]=testfile[0].apply(stem_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove numbers from the data\n",
    "import re\n",
    "for i in range(len(testfile)):\n",
    "    testfile[0][i] = re.sub('\\d', '', testfile[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>your still thinking?  cheer up buddi )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>forecast in sf for friday, may :  degrees.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drive past tatter cover w/o stop  promis mysel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wowzer! it' veri windy. not good for my allerg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>start of diet today  I think I have to face I ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0             your still thinking?  cheer up buddi )\n",
       "1         forecast in sf for friday, may :  degrees.\n",
       "2  drive past tatter cover w/o stop  promis mysel...\n",
       "3  wowzer! it' veri windy. not good for my allerg...\n",
       "4  start of diet today  I think I have to face I ..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testfile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the sentiment for test data\n",
    "predictions = pipeline25.predict(testfile[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  2,  3, 10,  2,  1,  7,  3,  1,  1,  3, 10,  3,  2,  3,  9,  3,\n",
       "        4,  4,  1,  1,  2,  3,  3,  2,  4,  3,  2,  2,  3], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the test data \n",
    "np.savetxt('pred25.dat',predictions,fmt = '%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
